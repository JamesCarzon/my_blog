[
  {
    "path": "posts/06_18_23_fifth/",
    "title": "From Gauss to Kolmogorov",
    "description": "A digest of the paper ``From Gauss to Kolmogorov: Localized measures of \ncomplexity for ellipses'' by Yuting Wei, Billy Fang, and Martin Wainwright \n(EJS, 2020).",
    "author": [
      {
        "name": "James Carzon",
        "url": "https://jamescarzon.github.io/"
      }
    ],
    "date": "2023-06-04",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nMuch can be said of the Gaussian\r\nand Rademacher width objects. At a high level, the width of a set carries\r\ninformation about how complicated that set is and, in turn, how complicated it\r\nis to estimate a parameter which is one among many members of that set. Methods for bounding the width of a set have been extensively studied.\r\nWe will consider a localized notion of Gaussian width. At a high level, one\r\nmay reason that the performance of a non-parametric estimation procedure should\r\nnot be evaluated based on its ability to distinguish the truth from remote\r\nalternatives – what really matters is its ability to distinguish the truth\r\nfrom nearby alternatives which are more likely to be confused for the truth.\r\nIf this intuition guides toward tighter estimation rates when using local\r\nnotions of width, then we are motivated to find easy means of estimating the\r\nlocal Gaussian width of a set about a point. A result of this kind is the\r\nsubject of a paper by Yuting Wei, Billy Fang, and Martin Wainwright (2020,\r\n(Wei, Fang, and J. Wainwright 2020)).\r\nThe basic idea is the following. There is some minimal dimension\r\n\\(k_*\\in\\{1,2,\\ldots,d\\}\\) for which \\(d\\)-dimensional data are approximated\r\nlocally by a \\(k_*\\)-dimensional plane to \\(\\delta\\)-accuracy. Then when the data\r\nare sufficiently regular in some sense, we can say that the local Gaussian\r\nwidth within a \\(\\delta\\)-ball is the same as \\(\\delta\\sqrt{k_*}\\) up to some\r\nuniversal constant. However, while Gaussian width is hard to compute, it is\r\nfairly easy to find \\(k_*\\). Thus this result is quite concise and useful.\r\nThis report is organized as follows. We state all of the definitions that we\r\nneed to make rigorous statements of the above ideas in\r\nbackground. Then we state\r\nthe results of the paper and their most immediate consequences in\r\nresults. We prove the first theorem in proofs, and we\r\nsketch the proof of the second (omitting a full proof which occupies five pages\r\nin our paper of interest). Finally, we summarize the entire report with the\r\ncentral idea and its consequences once again in discussion.\r\nBackground\r\nAgain, the Gaussian width of a set is some notion of its size or, roughly,\r\nthe difficulty of an estimation problem over it.\r\n\r\n\r\nDefinition 1  (Gaussian width) We define the Gaussian width of a set \\(S\\subset\\mbox{$\\mathbb{R}$}^d\\) as\r\n\\[\\begin{align*}\r\n    \\mbox{$\\mathcal{G}$}(S) &:= \\mbox{$\\mathbb{E}$}\\left[\\underset{u\\in S}{\\sup} \\langle u, w\\rangle\\right]. && \\left(w\\sim N(0, I_d)\\right)\r\n\\end{align*}\\]\r\n[Section 2.1 in (Wei, Fang, and J. Wainwright 2020)]\r\n\r\n\r\n\r\n\r\nDefinition 2  (Localized Gaussian width) The localized Gaussian width of \\(S\\) at \\(u^*\\in S\\) and scale \\(\\delta\\) is\r\nsimply \\(\\mbox{$\\mathcal{G}$}\\left((S-u^*)\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\right)\\), where \\(S-u^*\\) is the\r\ntranslation of \\(S\\) so that \\(u^*\\) coincides with the origin and \\(\\mbox{$\\mathbb{B}$}(\\delta)\\) is\r\nan \\(\\ell_2\\) ball of radius \\(\\delta\\). [Section 3.1 in (Wei, Fang, and J. Wainwright 2020)]\r\n\r\n\r\nThat is, it is the Gaussian width not of the whole of set \\(S\\) but is the width\r\nof the subset of \\(S\\) which contains those points which are within \\(\\ell_2\\)\r\ndistance \\(\\delta\\) from \\(u^*\\).\r\n\r\n\r\nDefinition 3  (Kolmogorov width) We define the Kolmogorov \\(k\\)-width of \\(S\\) as\r\n\\[\\begin{equation}\r\n    W_k(S) := \\underset{\\Pi_k}{\\min}\\text{ }\\underset{u\\in S}{\\max} \\left\\lVert u - \\Pi_k u\\right\\rVert_2,\r\n\\end{equation}\\]\r\nwhere the \\(\\Pi_k\\) are \\(k\\)-dimensional orthogonal linear projections. [Section 2.2 in (Wei, Fang, and J. Wainwright 2020)]\r\n\r\n\r\nIn words, the \\(k\\)-width of \\(S\\) is the maximum reconstruction error after\r\nprojecting \\(S\\) onto the best-approximating \\(k\\)-dimensional subspace. It happens\r\nthat, in the case where \\(S\\) is a space from which samples are observed, the\r\nproblem of estimating the best projection \\(\\Pi_k\\) is the same problem as\r\ncomputing the \\(k\\) first principal components of the data set. See Figure\r\n1.\r\n\r\n\r\n\r\nFigure 1: Intersecting an ellipse \\(S\\) and a \\(\\delta\\)-ball around \\(u^*\\in S\\), find the projection \\(\\Pi_k\\) which has the minimax reconstruction error over \\(S\\cap \\mbox{$\\mathbb{B}$}(\\delta)\\). That error is the local Kolmogorov \\(k\\)-width of \\(S\\) for \\(u^*\\)\r\n\r\n\r\n\r\nClearly if \\(k=d\\) the dimension of the ambient space, then there is only one\r\nprojection to consider (which is the identity projection) and ensures that\r\n\\(W_d(S)=0\\). On the other hand, if \\(k=0\\), then once again there is only one\r\nprojection to consider (which is the origin alone) and\r\n\\(W_0(S)=\\max_{\\theta\\in S}\\left\\lVert\\theta\\right\\rVert_2\\). Furthermore, we have that\r\n\\[\\begin{align*}\r\n    W_{k-1}(S) &\\geq W_{k}(S). && (k=1\\ldots,d)\r\n\\end{align*}\\]\r\nIn words, the Kolmogorov \\(k\\)-width decreases as the subspaces with which we\r\napproximate \\(S\\) increase in dimension; this fact is tedious to prove but\r\nintuitive enough and useful later.\r\n\r\n\r\nDefinition 4  (Critical dimension) Pick \\(\\delta>0\\) and \\(\\eta\\in(0, 0.1)\\). The critical dimension of \\(S\\) for \\(u^*\\)\r\nis\r\n\\[\\begin{equation}\r\n    k_*(u^*, \\delta) := \\min\\left\\{k\\in\\{1,2,\\ldots,d\\} :  W_k\\left((S-u^*)\\cap\\mbox{$\\mathbb{B}$}((1-\\eta)\\delta)\\right) \\leq 0.9\\delta\\right\\}.\r\n\\end{equation}\\]\r\n[Equation 8 in (Wei, Fang, and J. Wainwright 2020)]\r\n\r\n\r\nAs was suggested in intro, this quantity can be considered the minimal\r\ndimension for which there exists a \\(k_*\\)-dimensional projection that\r\napproximates a neighborhood of \\(S\\) around \\(u^*\\) to \\(0.9\\delta\\)-accuracy. In the\r\ncase where \\(S\\) is a space from which samples are observed, \\(k_*\\) may be\r\nconsidered the minimum number of the top principal components of the dataset\r\nneeded to capture \\(1-0.9\\delta\\) times the total variation in the data in the\r\n\\(\\ell_2\\) sense.\r\nNote that here we consider \\(0.9\\delta\\)-accuracy rather than simply\r\n\\(\\delta\\)-accuracy for the reason that we can only expect the latter in the case\r\nof \\(k_*=d\\), an uninteresting case. Instead we are much more interested in a\r\nsmall dimension at which we attain a reasonable representation of our set. We\r\ncould alternatively pick \\(\\eta\\in(0,t)\\) and pursue a \\((1-t\\delta)\\)-accurate\r\n\\(k_*\\)-dimensional subspace for \\(0<t<0.5\\), say, but while toggling the parameter\r\n\\(t\\) in this way may lead to interestingly different results in practice, the\r\nargument follows the same anyhow.\r\nFor the motivating examples of the paper, the set \\(S\\) is a finite-dimensional\r\nellipse \\(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\) which is defined as a ball\r\n\\(\\mbox{$\\mathbb{B}$}(\\theta^*; 1, \\left\\lVert\\cdot\\right\\rVert_{\\mu})\\) around \\(\\theta^*\\) and of radius \\(1\\),\r\nwhere\r\n\\[\\begin{align*}\r\n    \\left\\lVert\\theta\\right\\rVert_{\\mu} = \\sum_{i=1}^d \\frac{\\theta_j^2}{\\mu_j}. && (\\mu_1\\geq\\mu_2\\geq\\cdots\\geq\\mu_d\\geq 0)\r\n\\end{align*}\\]\r\nWe may ask how the difficulty of reconstructing \\(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\) with the\r\nprojection \\(\\pi_k\\) relates to the difficulty of reconstructing another ellipse\r\n\\(\\mbox{$\\mathcal{E}$}^*_{\\gamma}\\) (which is similarly defined).\r\n\r\n\r\nDefinition 5  Consider the set\r\n\\[\\begin{equation*}\r\n    \\Gamma(\\delta, \\Pi_k) := \\left\\{\\gamma\\in\\mbox{$\\mathbb{R}$}_{+}^d : \\underset{\\left\\lVert\\Delta\\right\\rVert_{\\mu}\\leq \\delta}{\\sup}\\left\\lVert\\Delta-\\Pi_k\\Delta\\right\\rVert_{\\gamma}^2\\leq 1\\right\\}\r\n\\end{equation*}\\]\r\nof all points \\(\\gamma\\) which furnish ellipses for which the reconstruction error for all \\(\\Delta\\in\\mbox{$\\mathcal{E}$}^*_{\\mu}\\) is small.\r\n\r\n\r\nIt is in terms of this set that we state our ``regularity conditions’’ for our central claim below.\r\n\r\n\r\nDefinition 6  If, of the ellipse \\(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\), we can say that\r\n\\[\\begin{equation}\r\n    \\delta\\sqrt{k_*(\\delta, \\theta^*)} \\gtrsim \\underset{\\gamma\\in\\Gamma(\\delta,\\Pi_{k_*})}{\\inf} \\sqrt{\\sum_{j=1}^d \\gamma_j},\r\n\\end{equation}\\]\r\nthen we say that \\(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\) is regular at \\(\\theta^*\\).\r\n\r\n\r\nThe premise of the paper is, again, as follows. If, of the ellipse \\(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\), we can say that it is regular at \\(\\theta^*\\), then the local Gaussian complexity of \\(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\) satisfies\r\n\\[\\begin{equation}\r\n    \\mbox{$\\mathcal{G}$}\\left(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\right) \\simeq \\delta\\sqrt{k_*(\\theta^*, \\delta)}.\r\n    \\tag{1}\r\n\\end{equation}\\]\r\nTo show Claim (1), we require an upper bound and a lower bound on the local Gaussian complexity. The upper bound is the subject of Theorem 1. The lower bound is the subject of Theorem 2.\r\nMain results\r\nToward the statement of a result of the form of equation , the authors offer an upper bound and a lower bound on the local Gaussian complexity of the ellipse. These are stated as follows.\r\n\r\n\r\nTheorem 1  (Upper bound) Given \\(\\delta>0\\), a tuple \\((k, \\Pi_k)\\), and some \\(\\theta^*\\in\\mbox{$\\mathcal{E}$}\\),\r\n\\[\\begin{equation*}\r\n    \\mbox{$\\mathcal{G}$}\\left(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\right) \\leq \\delta\\sqrt{k} + \\underset{\\gamma\\in\\Gamma(\\theta^*,\\delta,\\Pi_k)}{\\inf} \\sqrt{\\sum_{j=1}^d \\gamma_j}.\r\n\\end{equation*}\\]\r\n[Theorem 1 in (Wei, Fang, and J. Wainwright 2020)]\r\n\r\n\r\nThe proof of this theorem is reconstructed in the proofs section.\r\n\r\n\r\nTheorem 2  (Lower bound) There exist universal constants \\(c_1, c_2 > 0\\) such that for all \\(\\theta^*\\in\\mbox{$\\mathcal{E}$}\\),\r\n\\[\\begin{equation*}\r\n    \\mbox{$\\mathcal{G}$}\\left(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\right) \\geq c_1\\delta\\sqrt{1-\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}^2}\\sqrt{k_*(\\theta^*, \\delta)}\r\n\\end{equation*}\\]\r\nfor all \\(\\delta\\in\\left(0,c_2\\Phi^{-1}\\left((\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}^{-1}-1)^2\\right)\\right)\\). [Theorem 2 in (Wei, Fang, and J. Wainwright 2020)]\r\n\r\n\r\nThe proof of this theorem is sketched in proofs. Now we restate equation  formally.\r\nThe lower bound in this theorem is immediate from . The upper bound can be drawn quickly from  by simply noting that when the\r\nTo further illustrate the use of the above result, the following theorem assures the reasonable scaling of the critical dimension with \\(\\delta\\) and and the ease with which it is approximately computed.\r\nProofs and sketches\r\n\r\n\r\nProof (Proof of upper bound). For \\(\\Delta\\in\\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\) and \\(\\Pi_k\\) a \\(k\\)-dimensional orthogonal projection, write \\(\\Delta=\\Pi_k\\Delta + (\\Delta-\\Pi_k\\Delta)\\). Then\r\n\\[\\begin{align*}\r\n    \\mbox{$\\mathcal{G}$}\\left(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\right) &= \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta\\in \\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)}{\\sup} \\langle w,\\Delta\\rangle\\right]\\\\\r\n        &\\leq \\underset{T_1}{\\underbrace{\\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta}{\\sup} \\langle w,\\Pi_k\\Delta\\rangle\\right]}} + \\underset{T_2}{\\underbrace{\\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta}{\\sup} \\langle w,\\Delta-\\Pi_k\\Delta\\rangle\\right]}},\r\n\\end{align*}\\]\r\nleaving the task to bound the terms \\(T_1\\) and \\(T_2\\) separately.\r\n(Bounding \\(T_1\\).) Write\r\n\\[\\begin{align*}\r\n    \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta}{\\sup} \\langle w,\\Pi_k\\Delta\\rangle\\right] &= \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta}{\\sup} \\langle \\Pi_k w,\\Pi_k\\Delta\\rangle\\right] && ((I-\\Pi_k)w\\perp \\Pi_k\\Delta)\\\\\r\n        &\\leq \\underset{\\Delta}{\\sup}\\left\\lVert\\Pi_k\\Delta\\right\\rVert_2 \\mbox{$\\mathbb{E}$}\\left\\lVert\\Pi_k w\\right\\rVert_2 && (Cauchy-Schwarz)\\\\\r\n        &\\leq \\delta \\sqrt{k}\r\n\\end{align*}\\]\r\nusing the fact that \\(\\left\\lVert\\Delta\\right\\rVert_2\\leq \\delta\\) by definition and that\r\n\\[\\begin{align*}\r\n    \\mbox{$\\mathbb{E}$}\\left\\lVert\\Pi_k w\\right\\rVert_2 &\\leq \\sqrt{\\sum_{i=1}^d \\mbox{$\\mathbb{E}$}(\\Pi_k w)_i^2} && (Jensen)\\\\\r\n        &\\leq \\sqrt{\\sum_{i=1}^d \\mbox{$\\mathbb{I}$}\\left\\{i\\leq k\\right\\}}\\\\\r\n        &= \\sqrt{k}\r\n\\end{align*}\\]\r\nsince \\(\\Pi_k w\\) has the same distribution as a \\(k\\)-dimensional standard Gaussian random variable projected up into \\(d\\)-dimensional space and then rotated according to \\(\\Pi_k\\).\r\n(Bounding \\(T_2\\).) Let \\(A(\\gamma)=\\text{diag}(\\sqrt{\\gamma_1}, \\sqrt{\\gamma_2}, \\ldots,\\sqrt{\\gamma_d}).\\) Then write\r\n\\[\\begin{align*}\r\n    \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta}{\\sup} \\langle w,\\Delta-\\Pi_k\\Delta\\rangle\\right] &= \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta}{\\sup} \\langle Aw,A^{-1}(\\Delta-\\Pi_k\\Delta)\\rangle\\right]\\\\\r\n        &\\leq \\underset{\\Delta}{\\sup} \\left\\lVert A^{-1}(\\Delta-\\Pi_k\\Delta)\\right\\rVert_2 \\mbox{$\\mathbb{E}$}\\left\\lVert Aw\\right\\rVert_2.\r\n\\end{align*}\\]\r\nOf the first factor, note that for all \\(\\gamma\\in\\Gamma(\\delta,\\Pi_k)\\) we have\r\n\\[\\begin{equation*}\r\n    \\left\\lVert A(\\gamma)^{-1}(\\Delta-\\Pi_k\\Delta)\\right\\rVert_2 = \\left\\lVert\\Delta-\\Pi_k\\Delta\\right\\rVert_{\\gamma}\\leq 1\r\n\\end{equation*}\\]\r\nfor all \\(\\left\\lVert\\Delta\\right\\rVert_{\\mu}\\leq 1\\) by Definition .\r\nOf the second factor note that\r\n\\[\\begin{align*}\r\n    \\mbox{$\\mathbb{E}$}\\left\\lVert Aw\\right\\rVert_2 &\\leq \\sqrt{\\sum_{i=1}^d \\mbox{$\\mathbb{E}$}(A w)_i^2} && (Jensen)\\\\\r\n        &= \\sqrt{\\sum_{i=1}^d \\gamma_i}.\r\n\\end{align*}\\]\r\nIt follows that\r\n\\[\\begin{equation*}\r\n    \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta}{\\sup} \\langle w,\\Delta-\\Pi_k\\Delta\\rangle\\right] \\leq \\underset{\\gamma\\in\\Gamma(\\delta,\\Pi_k)}{\\inf}\\sqrt{\\sum_{i=1}^d \\gamma_i}\r\n\\end{equation*}\\]\r\nsince the left-hand side does not depend on the \\(\\gamma\\). Combining this result with the bound on \\(T_1\\) concludes the proof for Theorem 1.\r\n\r\n\r\n\r\n\r\nProof (Sketch of proof of lower bound). Consider two separate cases.\r\n(Case 1.) Suppose that \\(\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}\\leq\\frac12\\). The first step toward the claim in this setting is to show that\r\n\\[\\begin{equation*}\r\n    \\mbox{$\\mathcal{G}$}\\left(\\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\right) \\geq \\mbox{$\\mathcal{G}$}\\left(\\mbox{$\\mathbb{B}$}\\left(\\frac{3}{10}\\delta\\right)\\cap E_{k`_*}\\right),\r\n\\end{equation*}\\]\r\nwhere \\(E_k\\subset\\mbox{$\\mathbb{R}$}^d\\) is the subspace spanned by \\(\\{e_1,\\ldots,e_k\\}\\) and \\(k`_*\\geq k_*\\). In words, if \\(\\theta^*\\) is close to the center of the ellipse, then its associated local Gaussian complexity is bounded below by the local Gaussian complexity of a \\(k`_*\\)-dimensional ball. It can be checked directly that the right-hand side of the above inequality is equal to \\(\\frac{3}{10}\\delta\\sqrt{k`_*}\\), and by the assumption of this case we have that\r\n\\[\\begin{equation*}\r\n    \\frac{3}{10}\\delta\\sqrt{k`_*} \\geq \\frac{3}{10}\\delta\\sqrt{1-\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}^2}\\sqrt{k_*(\\theta^*,\\delta)},\r\n\\end{equation*}\\]\r\nwhich is the result. What remains to be seen is that that inequality is in fact true. Loosely speaking, it is indeed true because the set intersection of the right-hand complexity expression is smaller than the set intersection of the left-hand complexity expression.\r\n(Case 2.) Suppose that \\(\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}\\geq\\frac12\\). The gist of Lemmas 1 and 2 is that there exists a vector \\(\\theta^{\\dagger}\\in\\mbox{$\\mathcal{E}$}\\) and a packing\r\n\\[\\begin{align*}\r\n    \\Xi &= \\{\\theta^{\\dagger}+\\sigma^S: S\\in\\mbox{$\\mathcal{J}$}, \\sigma^S \\text{ $s$-sparse}\\} \\subset \\mbox{$\\mathcal{E}$},\\text{ where}\\\\\r\n    \\mbox{$\\mathcal{J}$}&\\subset \\mbox{$\\mathcal{P}$}(\\{\\lfloor(k_*-1)/8\\rfloor,\\ldots,\\lfloor(k_*-1)/4\\rfloor\\})\\text{ and}\\\\\r\n    s &:= \\rho\\frac{k_*-1}{16} &&(\\rho\\in(0,1))\r\n\\end{align*}\\]\r\nsuch that\r\n\\[\\begin{align*}\r\n    \\lvert\\Xi\\rvert &\\geq \\begin{pmatrix}\r\n        \\lfloor\\frac{k_*-1}{16}\\rfloor \\\\\r\n        s\r\n    \\end{pmatrix},\\text{ and}\\\\\r\n    \\delta^2 &\\leq \\left\\lVert\\theta^S - \\theta^*\\right\\rVert_2^2 \\leq \\left(\\frac{4}{1-\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}^2}\\right)\\delta^2.\r\n\\end{align*}\\]\r\nAll this is to obtain a (large but tractable) collection of vectors \\(\\Delta^S\\in\\mbox{$\\mathcal{E}$}_{\\theta^*}\\cap\\mbox{$\\mathbb{B}$}(\\delta)\\) proportional to \\(\\Tilde{\\theta}-\\theta^*\\) where \\(\\Tilde{\\theta}\\in\\Xi\\) so that\r\n\\[\\begin{equation}\r\n    \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Delta\\in \\mbox{$\\mathcal{E}$}^*_{\\mu}\\cap\\mbox{$\\mathbb{B}$}(\\delta)}{\\sup} \\langle w,\\Delta\\rangle\\right] \\geq \\mbox{$\\mathbb{E}$}\\left[\\underset{\\Tilde{\\theta}\\in\\Xi}{\\max} \\langle w,\\Delta^S\\rangle\\right].\r\n\\end{equation}\\]\r\nA further Lemma 3 takes the conditions for Theorem  and combines it with the result of Lemma 2 to show that the right-hand side of the above inequality is an upper bound for \\(\\delta\\sqrt{1-\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}^2}\\sqrt{k_*}\\) up to some universal constant. The argument for this step is somewhat similar to the part of the Proof of Theorem 1 () in that one can observe that the sparsity of the \\(\\Delta^S\\) zero out \\(d-k^*\\) entries of the Gaussian vector \\(w\\) so that, by H\"older, the \\(\\mbox{$\\mathbb{E}$}\\left\\lVert w\\right\\rVert_{\\infty}\\) looks like \\(\\sqrt{k_*}\\) and the \\(\\sup\\left\\lVert\\Delta^S\\right\\rVert_1\\) looks like \\(\\delta\\sqrt{1-\\left\\lVert\\theta^*\\right\\rVert_{\\mbox{$\\mathcal{E}$}}^2}\\). This is, as one would expect, a gross oversimplification of the details of the full proof.\r\n\r\n\r\nDiscussion\r\nThe consequences of the results discussed in the body of this report are, as promised, quite immediate for estimation rates. The set-up of the relevant estimation problem is as follows. If \\(\\theta^*\\in\\mbox{$\\mathcal{E}$}\\) an ellipse and some samples \\(y\\sim N(\\theta^*, I_n)\\) are observed, then the least squares estimator\r\n\\[\\begin{equation*}\r\n    \\Hat{\\theta} := \\arg \\underset{\\theta\\in\\mbox{$\\mathcal{E}$}}{\\min} \\left\\lVert y-\\theta\\right\\rVert_2^2\r\n\\end{equation*}\\]\r\nenjoys the following property.\r\nThis result is quite similar to what we already know about the relation between global Gaussian width and least squares estimation rates on ellipses. This topic is discussed at length in (J. Wainwright 2019).\r\nCan these results for bounding the local Gaussian width be imported to the question of bounding global Gaussian width? Not immediately can they be, but consider this. The hardest vector \\(\\theta^*\\in\\mbox{$\\mathcal{E}$}\\) to estimate is the zero vector since this is where the ellipse is the ``widest,’’ and the critical dimension of the ellipse around \\(0\\) is naturally going to be higher than the critical dimension anywhere else. Although \\(\\mbox{$\\mathcal{G}$}(\\mbox{$\\mathcal{E}$}_0\\cap\\mbox{$\\mathbb{B}$}(\\delta))\\) is not exactly \\(\\mbox{$\\mathcal{G}$}(\\mbox{$\\mathcal{E}$})\\), the two help capture the minimax difficulty of the estimation problem over \\(\\mbox{$\\mathcal{E}$}\\).\r\n\r\n\r\n\r\nJ. Wainwright, Martin. 2019. High-Dimensional Statistics: A Non-Asymptotic Viewpoint. Cambridge Series in Statistical and Probabilistic Mathematics. Cambridge University Press.\r\n\r\n\r\nWei, Yuting, Billy Fang, and Martin J. Wainwright. 2020. “From Gauss to Kolmogorov: Localized Measures of Complexity for Ellipses.” Electronic Journal of Statistics 14 (2). https://doi.org/10.1214/20-EJS1739.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/06_18_23_fifth/img/kolm_k_width.jpg",
    "last_modified": "2025-09-02T21:48:54-04:00",
    "input_file": {}
  },
  {
    "path": "posts/09_20_22_fourth/",
    "title": "History, meet your match!",
    "description": "An exposition of the computer model calibration method originated in the \nfield of oil reservoir engineering known as \"history matching.\"",
    "author": [
      {
        "name": "James Carzon",
        "url": "https://jamescarzon.github.io/"
      }
    ],
    "date": "2023-06-04",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nSuppose, for the sake of an analogy, that your name is Daniel Plainview and\r\nthat your milkshake doesn’t taste like it used to. Something’s off about it.\r\nAre there Oreo chunks at the bottom that you just didn’t catch earlier? Is the\r\nextra Nesquik powder clumping up? You have to try a little bit harder to yield\r\nthe same volume of shake now than you did on first suck, and you require a bit\r\nof trial and error to find the optimal technique.\r\nIf this sounds like a problem that you have faced before (and suppose, for the\r\nsake of my argument, that it does), then you might be an oil reservoir\r\nengineer.1 Daniel’s strategic approach to\r\nthe problem of pumping petroleum in the film There Will Be Blood is not\r\ndescribed in exceedingly technical detail; the dramatic intrigue comes from his\r\ncomplex personal machinations and manipulations, not the trivia of maintaining\r\nOSHA-compliant wells. In the sequel, There Will Be Sweat, Daniel does have to\r\npivot into the natural gas industry, and there is a long, boring, drawn out\r\nsequence where he goes down a Wikipedia rabbit hole on different accidents that\r\noccurred in the United States related to natural gas production. But one can reasonably presume that oil pumping is a non-trivial\r\naffair since it requires very expensive straws that are designed for drinking\r\nextremely deep “milkshakes” found in glasses of complex shapes (and part of my\r\npoint is that it would make for a really good movie I think if they leaned into\r\nthis aspect of the industry a bit more in the movie). It’s a complex\r\nengineering endeavour, and there was room for data science to improve it once\r\ncomputers became accessible to the engineers who cared about it. The state of\r\nthe art method for a particular aspect of the industry as of the 1970s is this\r\nmethod called “history matching.”\r\nIn this post, I will explain what this method is and how it is related to other\r\napplications and ideas in data science. As it turns out, history matching is\r\nemployed in many problems nowadays, but the literature on its theoretical\r\nguarantees and statistical properties still seems to be somewhat\r\nunderdeveloped. One of my current projects studies the method while regarding\r\nit as a means for uncertainty quantification, which is slightly different from\r\nits original use and should serve as an independent post in the future. For\r\nnow, I will focus on the application to computer model calibration.\r\nWhat is a history match?\r\nLet there be something we can measure. If we own an oil well, then maybe we can\r\neasily measure the amount of oil we produce in a week as well as the oil\r\npressure at the point where we’re drilling. Call the space of (production,\r\npressure) pairs \\(Y\\). Let there also be something that we can’t measure but\r\nwhich has an effect on the things that we can. In our example, maybe the\r\nporosity of the rock in which the reservoir of oil is found is hard to measure,\r\nbut it will effect how much oil is sitting inside and thus how much can be\r\nproduced at that location. Call the space of possible porosities \\(X\\). Let\r\n\\(F: X\\rightarrow Y\\) be a computer program or mathematical model for a\r\ndrilling procedure which takes as input some point in \\(X\\) and gives a point in\r\n\\(Y\\) as the procedure’s predicted output.\r\nIf we are scientists, then maybe we are interested\r\nin the porosity for its own sake. If we are a drilling company, then maybe we\r\nare more specifically interested in how the porosity will affect our\r\nproductivity next week. We’ll suppose that the quantity of interest is\r\ndescribed by another program or function \\(\\lambda: X\\rightarrow\\mathbb{R}\\), and\r\nso the space of possible future production levels is \\(\\mathbb{R}\\).\r\nOur pipeline – if you will – for making some prediction for next week’s\r\nproduction level is as follows. Let \\(x\\in X\\) be the true porosity, \\(y\\in Y\\)\r\nbe the true (production, pressure) pair, and \\(z\\in Y\\) be the (production,\r\npressure) pair that was actually measured, as in Figure\r\n1. (Maybe there was some small amount\r\nof error when measuring.) Our goal is to first take \\(z\\) and find a point\r\n\\(x'\\in X\\) such that \\(F(x')=z\\). Our point \\(x'\\) is our best guess for \\(x\\). Then\r\n\\(\\lambda x'\\) is our production prediction.\r\nIn practice, the pipeline is a bit more complicated than this. Maybe we would\r\nlike to think that for any point \\(x'\\in X\\), if \\(F(x')=z\\), then \\(x'=x\\). Firstly,\r\nwe should be prepared for the scenario in which our measurements \\(z\\) are\r\nslightly wrong since our measurements for pressure or volume of oil might be\r\nrounded off or estimated at some point. Secondly, even if we didn’t have this\r\nerror, it’s possible that \\(F\\) is a function which is not a one-to-one map. That\r\nis, if you draw its graph (say, production versus porosity) and then draw a\r\nhorizontal line at the production level, then it might not pass the\r\nhorizontal line test. Maybe two different porosities, \\(x'\\) and \\(x''\\) would\r\ndetermine the same production levels. Then which is the best prediction for\r\n\\(x\\)? For this reason, we will relax our goal. Rather than identifying a point\r\nprediction for \\(x\\), we will seek a set \\(\\Xi\\subset X\\) which includes all of our\r\nbest predictions for \\(x\\). In particular, we will take the set \\(\\Sigma\\) of all\r\n\\(y'\\in Y\\) such that \\(y'-z\\) is less than the maximum amount of error that we\r\nexpect to see from our instruments with which we measure production and\r\npressure, and then compute \\(\\Xi=F^{-1}(\\Sigma)\\), the set of all \\(x'\\in X\\) such\r\nthat \\(F(x')\\in\\Sigma\\). That is a reasonable goal.\r\n\r\n\r\n\r\nFigure 1: A schematic view of the problem pursued by history matching. Give constraints on \\(\\lambda x\\) from observations \\(z\\in Y\\) by estimating error \\(z-y\\) and finding the preimages \\(x\\in X\\) which are close to \\(z\\) up to that error level.\r\n\r\n\r\n\r\nHow to solve an inverse problem\r\nWith the problem and its participating objects described in the abstract, we\r\nneed to decide how to perform history matching concretely. We will see how\r\nfirst to write down an implausibility metric and then we will invert the\r\nmetric to obtain an\r\nimplausibility region over \\(X\\). Under some conditions on the function \\(F\\), the\r\ninversion step can be a relatively simple process. In general, the only\r\npractical solution is to get a Monte Carlo sample of metric values and\r\napproximate \\(\\Xi\\).\r\nImplausibility metric\r\nSuppose that \\(Y=\\mathbb{R}\\), just one scalar quantity, and of \\(F\\) it is known\r\nhow to compute the mean and covariance of the outcome. That is,\r\n\\[\\begin{align*}\r\n  \\mu(x) &= \\mathbb{E}[F(x)]\\text{, and}\\\\\r\n  \\sigma^2(x) &= \\mathbb{E}[F(x)^2] - \\mathbb{E}[F(x)]^2\r\n\\end{align*}\\]\r\nare both computable. Then the natural implausibility metric is\r\n\\[\\begin{equation*}\r\n  \\gamma(x) = \\frac{\\lvert\\mu(x)\\rvert}{\\sigma(x)}\r\n\\end{equation*}\\]\r\nbecause it accounts for uncertainty \\(\\sigma^2(x)\\) in a natural way. More\r\ngenerally, we may want to consider multiple measurements – in our motivating\r\noil reservoir example, the two measurements are production level and oil\r\npressure. Then we will assume that we can measure \\(D\\) quantities \\(F_i\\),\r\n\\(i=1,\\ldots, D\\) and then compute\r\n\\[\\begin{align*}\r\n  \\mu(x) &= (\\mathbb{E}[F_i(x)])_{i=1,\\ldots,D}\\text{, and}\\\\\r\n  \\Sigma(x) &= (\\mathbb{E}[F_i(x)F_j(x)] - \\mathbb{E}[F_i(x)]\\mathbb{E}[F_j(x))_{i,j=1,\\ldots,D}.\r\n\\end{align*}\\]\r\nTwo candidates for the role of this multi-measurement implausibility metric\r\nmost prominently present themselves in the literature. The first is an \\(L_2\\)\r\nnorm based metric,\r\n\\[\\begin{equation}\\label{eq:metric_1}\r\n  \\mathscr{I}(x) = \\mu^T(x)\\Sigma^{-1}(x)\\mu(x),\r\n\\end{equation}\\]\r\nand the second is an \\(L_\\infty\\) norm based metric,\r\n\\[\\begin{equation}\r\n  \\mathscr{I}(x) = \\underset{i}{\\max}\\lvert \\gamma_i(x)\\rvert,\r\n\\end{equation}\\]\r\nwhere the \\(\\gamma_i\\) are defined like \\(\\gamma\\) but for each component of \\(F\\).\r\nInversion step\r\nReferring back to Figure 1, we will use a choice of implausibility metric to\r\nobtain the set \\(\\Xi\\). This is simply the subset of \\(X\\) which produces small\r\nimplausibilities. On the one hand, one could tune the implausibility threshold\r\nso that the volume of \\(\\Xi\\) is fixed. (This is what I see history matching\r\npractitioners do most often.) On the other hand, one may desire a probabilistic\r\ninterpretation for \\(\\Xi\\) e.g. ``The true conditions / parameter levels lie in\r\n\\(\\Xi\\) with 95% confidence.’’ This requires some assumptions on the distribution\r\nof the data so that a notion of confidence is explicit. This is, in my opinion,\r\na harder question since its appropriateness depends on the quality of the\r\nanalyst’s modeling choices; this question could be treated more thoroughly in a\r\nlater post in lieu of expanding on recent work of my own. For reference, the\r\nformer approach to the inversion step is seen in (Johnson et al. 2020) for\r\nconstraining parameters which underly atmospheric aerosol climate models, and\r\nthen my forthcoming paper in Environmental Data Science will view those same\r\nmodels but provide probabilistic constraints. The preprint can be found on\r\narXiv (Carzon et al. 2023).\r\n\r\n\r\n\r\nCarzon, James, Bruno R. de Abreu, Leighton Regayre, Kenneth Carslaw, Lucia Deaconu, Philip Stier, Hamish Gordon, and Mikael Kuusela. 2023. “Statistical Constraints on Climate Model Parameters Using a Scalable Cloud-Based Inference Framework.” Environmental Data Science. https://arxiv.org/abs/2304.03127.\r\n\r\n\r\nJohnson, Jill S., Leighton A. Regayre, Masaru Yoshioka, Kirsty J. Pringle, Steven T. Turnock, Jo Browse, David M. H. Sexton, et al. 2020. “Robust Observational Constraint of Uncertain Aerosol Processes and Emissions in a Climate Model and the Effect on Aerosol Radiative Forcing.” Atmospheric Chemistry and Physics 20 (15): 9491–9524. https://doi.org/10.5194/acp-20-9491-2020.\r\n\r\n\r\nIn other words, if you might not be an oil reservoir engineer, then\r\nthis doesn’t sound like a problem that you have faced before. Since most people\r\nare not oil reservoir engineers, most people might not be. It follows that most\r\npeople cannot relate to my analogy. For this reason I encourage you all to one\r\nday try a milkshake and decide for yourself later with better information\r\nwhether this blog post is worth your time rather than deciding against reading\r\nit on account of it not being relevant to you.↩︎\r\n",
    "preview": "posts/09_20_22_fourth/img/oil_reservoir_resize.png",
    "last_modified": "2025-08-23T22:54:36-04:00",
    "input_file": {}
  },
  {
    "path": "posts/08_16_21_third/",
    "title": "On answering the wrong question",
    "description": "Some examples of how statistical hypothesis testing sometimes answers \ndifferent questions than we would like to ask.",
    "author": [
      {
        "name": "James Carzon",
        "url": "https://jamescarzon.github.io/"
      }
    ],
    "date": "2022-06-21",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nSometimes we find ourselves answering a different question than we’d been\r\nasked. We’ve all been there. One time I’d spent several minutes explaining the\r\noverlap in Pittsburgh bus route coverage to a freshman at CMU who had asked me\r\n“Where does the Carnegie Museum of Art sit among your favorite coffee\r\nshops?” So trust me, I’ve been there (and their cafe’s lattes are\r\nmiddle-of-the-road).\r\nAnother classic example of answering the wrong question is the interpretation\r\nof hypothesis tests in statistics. Say for the sake of discussion that I’m an\r\nordinary seismologist who has wandered into your home, and you ask me, “What’s\r\nthe probability that an earthquake happens in Yellowstone National Park this\r\nyear?” Bumbling and jabbering under my breath, I help myself to your dusty\r\nfloor and secure myself against the door so that no one may leave as I respond\r\nto your plainly stated question, answering: “Well, you see, within ninety-five percent error bars we can say with asymptotic certainty that that the\r\nlikelihood of a seismic event in Yellowstone in the next year is predicted to\r\nbe very unlikely with a confidence level of 0.05 and a \\(P\\)-value of 1.21.” You\r\nthink to yourself, are all seismologists like this? but you splurt out (rudely),\r\n“Hey, wait a minute! I didn’t ask you about the likelihood. I asked you\r\nabout the probability! And I certainly didn’t need you to conceal your sneaky\r\nsubstitution amongst uninteresting remarks on \\(P\\)-values and confidence\r\nlevels.” But alas, every scientist knows that a simply stated conclusion is a\r\nfalse one, and so every caveat known to be relevant to any statistical\r\nhypothesis ever must be rattled off upon its statement, like possible side\r\neffects to a new drug during a Super Bowl spot.\r\nIn this post, let’s ask some of the questions that we’re not allowed to ask in\r\nan introductory statistics class, the questions that scientists aren’t allowed\r\nto answer straightforwardly because their statistics profs say so. The\r\nhypothesis testing process that is so\r\nfundamental to the conduct of statistics in the real world - or so they would\r\nhave you believe1 -\r\nis actually such a rigid concept that the\r\nrules may seem unintuitive and the results, uninteresting. It is time now to\r\ndiscuss of these nagging issues.\r\nA preference for positive results\r\nWhen we first learn how to test hypotheses, we learn to test “simple”\r\nhypotheses. Let us start here.\r\nRecall the hypothesis testing process. A\r\nresearcher may ask whether it is likely the case that a treatment that they are\r\nadministering to a portion of their experiment participants is causing a\r\nsignificant difference in their health outcomes. The optimistic researcher\r\nwould like to see that the people receiving the treatment are turning out\r\nbetter than are the people receiving no treatment, and so they perform a\r\n“hypothesis test” with the “null hypothesis” that the treatment effect (call it\r\n\\(\\beta\\)) is not significant (i.e. \\(\\beta=0\\)). If we find that this hypothesis\r\nis very unlikely to be true given the data that we collect in the experiment,\r\nthen we will reject the hypothesis. If it is not very unlikely, then we will\r\nsay that we fail to reject the hypothesis and that it could be that the\r\ntreatment effect \\(\\beta\\) is not significant. We never “confirm” that \\(\\beta=0\\)\r\nbecause we cannot prove it to be true without perfect knowledge about how the\r\ntreatment affects people.\r\nTo test the hypothesis, we define a “test statistic”\r\nand compute the probability that some random variable takes on a value as\r\nextreme as the value of the test statistic. Which random variable we use\r\ndepends on our null hypothesis, but if this topic is unfamiliar, suffice it to\r\nsay that if the probability of obtaining as extreme a value as our test\r\nstatistic is really low,\r\nthen we may say that there’s enough evidence to conclude that the null\r\nhypothesis is probably false and that \\(\\beta\\neq 0\\). The treatment has an\r\neffect.\r\nThis is the typical approach to testing statistical hypotheses, but notice that\r\nthere are some seemingly arbitrary limitations to this highly specific process.\r\nFor example, if we are looking for a treatment effect, then we first pretend\r\nlike there is no effect and then test whether we can reject such a pretension.\r\nWhat if we wanted to test whether a treatment had no effect? Is that allowed?\r\nIt’s a little tricky. When we compute a test statistic, we compute it in such a\r\nway so that we can say what it’s probability distribution is only supposing\r\nthat the null hypothesis is true. For example, if our test statistic is the\r\naverage body temperature of a patient receiving the treatment, then under the\r\nassumption that the treatment causes no change in their condition, we can say\r\nthat their average body temparature should be distributed around an average\r\nvalue of about 98 degrees Fahrenheit. If we observe that the patients’\r\ntemperatures are far away from 98 on average, then it sure seems like the\r\ntreatment is having an effect!\r\nHowever, if instead we wanted to check whether the treatment did not have an\r\neffect, then we might try starting off with the null hypothesis that their\r\naverage temperature is not 98 degrees. If we can show that this\r\nhypothesis is unlikely to be true, then we can reject this claim and say that\r\nthere is not an effect. (If we used the hypothesis \\(\\beta=98\\), then the best we\r\ncould do with that test is “fail to reject” the claim that \\(\\beta=98\\) rather\r\nthan proving it.) So now we suppose that \\(\\beta\\neq 98\\). How do we test this?\r\nDo we pretend that \\(\\beta=100\\) and compare with our patients’ data? Why not\r\n\\(98.1\\)? Why not \\(98.001\\)? It is not clear how to compare our data with our\r\nhypothesis in this scenario. Thus the problem then arises that if you want to\r\nask a statistician for negative results, then you’re out of luck. Our\r\nhypothesis test process only knows how to handle questions which ask for\r\npositive results.\r\nUnphysical specificity\r\nIf, back when I was four years old, you (found me and) asked me if the number\r\n100 is a big number, then I probably would have told you, Yes, it is. If you\r\nasked ten-year-old me the same question, then I probably would have said no.\r\nBut it’s the same number! you tell me (a ten-year-old, now damaged by your\r\ncharmless consultation).\r\nIt would be in our interest to settle consistently, completely,\r\nonce-and-for-all what constitutes statistically “significant” evidence for or\r\nagainst a hypothesis. The difficulty that we face in doing this rigorously is\r\nthat there is no physical law which governs the cutoff point for good or bad\r\nevidence. At once there is the fact of the matter into which we inquire with\r\nour test - for example, there is a true and absolute body temperature which an\r\nexperiment participant should expect to experience as a result of their\r\nparticipation - and there is our limited view of the fact - limited by the\r\nnumber of people participating, by the precision of our thermometers, and so\r\non. There is no piece of technology capable of deciding from our limited view\r\nwhat the truth is, and there is no method of obtaining the truth by philosophy\r\nalone, either. The only propositional knowledge that we have that is not\r\nsubject to revision is the combination of impressions gained directly through\r\nthe senses as well as any statements made by the pope ex cathedra.\r\nFor this reason, when we test a hypothesis, we have to make our judgment on\r\nthat hypothesis with the knowledge that we are tolerating the possibility of\r\nmaking errors. In particular, there is a possibility of rejecting a hypothesis\r\nthat is actually true (which we call a Type I error) as well as of failing to\r\nreject a hypothesis that is actually false (which we call a Type II error).\r\nSuppose we establish for ourselves the principle that we should try to reject\r\nas many false hypotheses as we can in our time on Earth but not falsely reject\r\nmore than 5% of the true hypotheses. If we figure out the probability\r\ndistribution of a test statistic with which we can test our hypotheses, then\r\nlet’s just mark off the parts of the distribution which represent the most\r\nextreme 5% of values that the statistic can take. If the statistic for a test\r\nlands in one of those marked-off regions, then we will reject the hypothesis\r\nbeing tested. If it’s a bell curve-like distribution, then that looks something\r\nlike this:\r\n\r\n\r\n\r\n\r\n\r\n\r\nFigure 1: Some distribution with a hypothesis rejection region highlighted\r\n\r\n\r\n\r\nHowever, it somehow feels inappropriate to allow our treatment of evidence to\r\nbe this black and white. Should it be the case that test statistics which fall\r\njust barely outside of the rejection region lead to retained hypotheses while\r\ntest statistics which fall just barely inside lead to rejections? It doesn’t\r\nfeel like there’s a qualitative difference in small differences at the boundary\r\nwhen there isn’t a difference in small differences somewhere in the middle.\r\nThis uncomfortable fact about hypothesis testing merely helps to illustrate\r\none of the shortcomings of formal statements about statistical observations.\r\nIt’s not the case that we’ve proved anything interesting when we reject a\r\nhypothesis on some basis of statistical evidence. We are merely summarizing the\r\nhypothesis in some manner that is precise yet arbitrary. We have assigned some\r\nnumber to the hypothesis and we have described that number as being\r\n“rejectable” or “not rejectable,” but this particular concept of “rejectable”\r\nhere is so specific that it should not be mistaken for ordinary language terms\r\nlike “believable” or “interesting” or “possibly worth studying further.” It is\r\nuseful only insofar as it makes efficient and fairly consistent the process of\r\nactually deciding which hypotheses are believable, interesting, or possibly\r\nworth studying further.\r\nIndividuals don’t care about statistical confidence\r\nWhen one poses a hypothesis for statistical testing, there is an assumption\r\nthat their data points are all distributed similarly so that they can share\r\ninformation with each other and give some idea what the underlying distribution\r\nlooks like. This is the assumption of “independent and identically distributed\r\ndata” (or the i.i.d. assumption). In reality, this assumption is not obvious.\r\nFor example, in a medical study maybe a researcher would hope that the people who participate\r\nin the study share general traits so that no one has a wildly different\r\nreaction to a treatment and demonstrates an uncommon, unexpected side-effect.\r\nOtherwise, maybe they would hope that if any uncommon traits are represented,\r\nthen alternative traits are also represented, such as having both overweight and\r\nunderweight, old and young, healthy and ill participants, so that a difference\r\nin outcomes can be measured. These are all reasonable considerations for a\r\nresearcher who is trying to identify an average treatment effect, but they\r\ndon’t necessarily mean anything to an individual who faces the choice of\r\nwhether or not to receive the treatment.\r\nTo illustrate this point, consider the following scenario. A potassium\r\nsupplement is recommended to you by your doctor, and they assure you that it\r\nwill make you feel better with high confidence.2 How do they know? Well, the\r\nsupplement was administered to a large cohort of study participants and 95% of\r\nthose participants fell within an interval of “good” potassium levels in their\r\nblood, say in the whitened-out region of 1. Looking at\r\nthe curve, however, you note that at the same time about 95% of participants\r\nfell outside of the interval of “perfect” potassium levels, as depicted in\r\n2. Here is another 95% confidence set that your doctor\r\ncould have showed you which is as valid as the previous one yet emphasizes a\r\nless optimistic interpretation of the study outcomes. Being the shrewd\r\ninvestigator that you are, you attend to your fear of possibly being an outlier-\r\npatient and very likely not being among those most rewarded for receiving\r\ntreatment and forego the treatment.\r\n\r\n\r\n\r\nFigure 2: Some distribution with a weird hypothesis rejection region highlighted\r\n\r\n\r\n\r\nAre you wrong to make this judgment? as many people may do when they forego\r\nmedical interventions in fear of negative side effects. I answer that this is\r\nnot necessarily wrong, but if it seems at all odd that one would report on a\r\nnon-standard confidence interval of the form \\((-\\infty, L]\\cup[U,\\infty)\\) and\r\nlet their decision be determined by that interval, then it may be a fun\r\nexercise to convince yourself that a confidence interval of the form \\([L, U]\\)\r\nalways makes sense. Which cases do you want to capture with your interval? The\r\n“normal” ones or the “abnormal” ones?\r\n\r\nI’m really not accusing anyone in particular. There are\r\nnecessary constraints on how many times instructors of introductory statistics\r\nclasses can tell their students that this or that statistical method is\r\nactually wrong and not useful, and students sometimes just want to know if\r\ntheir answer is “correct” so that they can repeat their answers on the exam.↩︎\r\nSuppose your blood potassium\r\nlevels matter a lot for feeling well.↩︎\r\n",
    "preview": "posts/08_16_21_third/img/trains_passing_resize.png",
    "last_modified": "2022-06-21T15:54:49-04:00",
    "input_file": {}
  },
  {
    "path": "posts/07_05_21_second/",
    "title": "What does elo measure?",
    "description": "A definition of elo rating. An analysis of a chess game of mine. An inaugural \nentry in an amateur chess diary, if you will.",
    "author": [
      {
        "name": "James Carzon",
        "url": "https://jamescarzon.github.io/"
      }
    ],
    "date": "2021-08-16",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nIt is imperative that you establish your chess skill level as soon as possible. There is simply too much at stake to live your 21st century life in tactical darkness. If you seriously think that you can walk around inside this world with nothing but the minimal knowledge of how the pieces move and still hold your head high at night, then you’ve already lost. Mark my words, you will be the one left sitting on the curb outside Pizza Hut with your confidence shattered and your carpal tunnels throbbing while a confederacy of twelve-year-olds will be standing around you with their hands making knight-jump-shapes on their acne-ridden foreheads. There is no coming back from this disaster.\r\nAs a kid, I did not believe myself to be mathematically competent, and I assumed that good play of chess required some sort of talent for calculation. When I started playing chess in college, I marvelled at my opponents’ good fortune. I thought to myself as I lost time and again, I’d done nothing wrong! I traded pieces for pieces, I didn’t walk into check, and I kept my queen next to my king! How could I have lost?\r\nThe circumstances of the COVID-19 pandemic kindled a change in my attitude about the game. I found it to be an opportune activity to share remotely with my friends and a skill in which I was certainly capable of improving. The practice of learning to play better chess (as opposed to the practice itself of playing chess) is very satisfying now, because I no longer embarrass myself and have a renewed admiration for my ability to cling to mediocrity in a broad range of skills in which most people either find great success or total disdain.\r\nThis post is a reflection of my current state in the hobby of online chess. As an educational exercise and for curious readers, I want to document my thought process qualitatively a little. Additionally, in the interest of learning more about how my progress is measured, I investigate the “elo rating.” This investigation I share with you now.\r\nElo as proxy\r\nIt would be convenient to know your genuine world ranking in chess like how you know your height, but you can’t practically determine such a thing. The only way to decide how good people really are is to make everyone play against everyone else infinitely many times and then line up in such a way that no one is standing behind someone against whom they win more than half of the time. But such a tournament is impractical since we would not have anyone to wash our clothes or to clean after the horses on Mackinac Island, and so we will never know how good we really are.\r\nBut it is rather obvious that we may guess how good we are at the game, and to guess with improving certainty with more and more play, without ever actually measuring skill. To have a good guess, let’s just order everyone that you’ve played against according to your win percentage against them. You can stand in front of the people against whom you normally win, but you must stand behind those who beat you. How good is the person standing in front of you? And behind? Average their true rankings to approximate your own.\r\nOf course, this solution is no good since your opponents don’t know their true rankings either. Furthermore, it may be the case that two players against whom you consider yourself equally ranked do not consider themselves equally ranked, so this program of ordering everyone may be poorly defined.\r\nIn order to make up numbers to represent skill level, the elo rating system depends on the simple premise that a player’s true ability is not perfectly represented in any one game. Sometimes they play better than average and other times they play worse. Then, for example, if they are supposedly at rating \\(X\\) and they are winning frequently against players of ratings greater than \\(X\\), then this is a sign that their rating is underestimated and should be increased. Usually, a player’s performance is assumed to respect a curve that looks like the following graph.\r\n\r\n\r\n\r\nThis curve is of an “extreme value distribution,” also known as the Gumbel distribution. That is, it is a curve which shows the theoretical distribution of values of the maximum values of data samples which, in turn, are samples from some other distribution. A classic use case might be the following. Suppose a river runs through your property and you would like to know if the river is likely to rise enough to spill over your garden. You may know how high the river ran every day for the last ten years, but the only information that is relevant to you is the maximum height this year. Taking the maximum heights observed in each of the previous ten years as your data sample, you can compute their average and their standard deviation to find a Gumbel distribution which describes the probabilities of different ranges of river heights.\r\nIt is probably not true that anyone’s chess performance respects the Gumbel distribution. One could draw lots of other curves which would be just as believable descriptions of performance. However, the Gumbel distribution is a convenient choice for the purposes of a few calculations.\r\nIf I tell you that GM Autobus’ play is distributed like Gumbel random variable \\(A\\), with mean play at rating \\(2550\\), and FM Bindowcleaner’s play is distributed like \\(B\\), with mean play at \\(2150\\), then we should have the expectation that Autobus will beat Bindowcleaner fairly frequently. For the sake of making up some point of reference to explain how big this difference in rating is in terms of winning percentage, we decide as convention that a \\(+400\\) rating difference translates to probable winning odds of \\(10:1\\). So Autobus should be able to score 10 out of 11 points in an 11 game match against Bindowcleaner. In notation, write\r\n\\[\\frac{Pr(A\\text{ beats }B)}{Pr(B\\text{ beats }A)} = 10^{\\frac{R_A-R_B}{400}}.\\]\r\nOn the left is denoted the odds of a random variable pretending to be Autobus playing at a higher level than a random variable pretending to be Bindowcleaner. To say that “\\(A\\) beats \\(B\\)” is to say that \\(A\\) takes a number value higher than \\(B\\). On the right is an expression of those odds in terms of assumed rating; if the difference \\(R_A-R_B\\) is equal to \\(+400\\), then the righthand expression evaluates to \\(10\\). If \\(R_A-R_B=+800\\), then the righthand expression evaluates to \\(100\\). This makes sense. If Stockfish 14, the chess playing machine, has an assumed rating of \\(2950\\), then it should beat Autobus with odds 10 to 1. If it then faced off against Bindowcleaner, then it could do the following. It could say, “Hey GM Autobus! Why don’t you play 101 games for me against Bindowcleaner? If you win, then we’ll just say that I would have also won that game since I generally play better than you do. If you lose, however, then I will play the rematch against Bindowcleaner myself. Since I play better than you in 10 out of 11 games on average, I expect to be able to win 10 out of 11 of those 11 games that you are expected to lose to Bindowcleaner, thus preserving my legacy.” Ignoring the ethical difficulty of convincing a human to play for a computer, much less 101 games, the takeaway is that this equation describes the scenario which we have sought to describe.\r\nLet us algebraically extract some new information. Since it is vanishingly unlikely for \\(A\\) to equal \\(B\\) from a probability perspective, we will simply observe that either \\(A\\) beats \\(B\\) or \\(B\\) beats \\(A\\) in our scenario. Ignore draws. Then\r\n\\[Pr(A\\text{ beats }B)+Pr(B\\text{ beats }A)=100\\%=1,\\]\r\nso\r\n\\[Pr(B\\text{ beats }A)=1-Pr(A\\text{ beats }B).\\]\r\nCombining this with the first equation, we solve for \\(Pr(A\\text{ beats }B)\\) to obtain\r\n\\[Pr(A\\text{ beats }B) = \\frac{1}{1+10^{\\frac{R_B-R_A}{400}}}.\\]\r\nConveniently, this expression is related to our assumption that one’s chess performance follows a sort of curve like the Gumbel curve. The Gumbel curve is the graph of a function like\r\n\\[f(x) = \\frac{1}{\\beta}e^{-\\left(\\frac{x-\\mu}{\\beta}+e^{\\frac{x-\\mu}{\\beta}}\\right)},\\]\r\nwhere the number \\(\\mu\\) determines where the curve is centered and the number \\(\\beta\\) determines the horizontal scale. Let us take it as a fact now that if two random variables \\(A\\) and \\(B\\) follow Gumbel distributions with the same scale number \\(\\beta\\), then the random variable \\(B-A\\) is a random variable with a logistic distribution, meaning that it has a distribution defined by the function\r\n\\[g(x) = \\frac{e^{-\\frac{x-\\mu*}{\\beta}}}{\\beta\\left(1+e^{-\\frac{x-\\mu*}{\\beta}}\\right)^2},\\]\r\nwhere \\(\\mu*\\) is the center of the curve showing the distribution of \\(B-A\\). If we perform a clever calculus calculation, then we can obtain\r\n\\[Pr(B-A\\le x) = \\int_{-\\infty}^{x}f(y)dy = \\frac{1}{1+e^{-\\frac{x-\\mu*}{\\beta}}}.\\]\r\nThis function, this particular probability, is a function which looks similar to our expression for \\(Pr(A\\text{ beats }B)\\).\r\nIn particular, if \\(\\mu_*=R_A-R_B\\) and \\(\\beta=\\frac{400}{\\log 10}\\), then\r\n\\[P(A\\text{ beats }B) = P(B-A\\leq 0) = \\frac{1}{1+e^{\\left[-\\frac{R_B-R_A}{\\frac{400}{\\log 10}}\\right]}} = \\frac{1}{1+10^{-\\frac{R_B-R_A}{400}}}.\\]\r\nThis calculation is repeated from Arthur Berg’s explanation in Chance (Berg 2020). So it seems that this probability model for chess play is somehow justified by the convenience of this calculation. If we pretend that one’s performance follows this Gumbel curve, then we can say that the odds seen in games are structured in the way described concretely above: a \\(+400\\) rating difference translates to expected \\(10:1\\) odds of winning. To conclude, Elo doesn’t measure chess ability or ranking, but it is a somewhat sophisticated guess as to one’s relative winning odds against another player.\r\nDon’t trot out the queen\r\nUnderstanding the technical definition of chess rating has not been practically helpful for playing better chess in my experience, but I have learned a few things about how to adjust my play to opponents of different ratings. For example, I recognized early on in my career as an amateur that low rated players are forever begging to trick someone into falling for the “Scholar’s Mate.” Something like this is what they have in mind:\r\n\r\n\r\n\r\nIt’s a quick and annoying loss for the poor soul who doesn’t see it coming. However, in order to achieve this trick, you have to breach a generally true rule: you have to develop our queen piece early. This is typically a bad idea because it is easy for your opponent to simultaneously get their pieces into the center of the board while also attacking your queen. As you run the queen away over and over again, your other pieces don’t move and you end up falling behind. For this reason, it’s better to move your other pieces out before the queen.\r\nI think that it is at or around the 1000 elo rating in online chess play that everyone is smart enough not to try using the Scholar’s Mate as an old, reliable tool. Similar patterns do emerge sometimes. As an example that I may pleasantly share, I submit for your consideration the following game that I played against an opponent by the handle “PunisherFevzican9.”\r\n\r\n\r\nThe initial move 1. … c5 is the Sicilian Defense. Up to 4. Bc4, this game is a common position, but with 4. … f6 the database on Lichess.org is exhausted. This pawn push is considered a mistake because it allows me to break into the center, but it was not obvious to either of us in that moment. I just happened to play the best move next.\r\nWe trade pieces in the center on d4 until 7. Qxd4. Now my queen is developed and easily be attacked, and so comes 7. … d5. Unfortunately for my opponent, this gives me the option to attack the vacated f7 square with a bishop-queen battery, almost like how the Scholar’s Mate looks, except now my queen can’t be dislodged. All the pawns are too far advanced. I play 8. Qd5, eying f7. Then 8. … Qe7 defends that square, so I bring my knight to b5, now getting ready to fork the king and rook or maybe just help in the attack. The black queen now runs around trying to find something dangerous to do but can’t figure anything out. With 13. Qxe7+, I trade queens, thinking that I have a strong enough attack without the queens on the board to checkmate soon.\r\nAt this point I spend some time looking for a possible checkmate pattern. I saw that the king had two squares to move to: c7 and e8. If I could hold the king in place, then that would make it hard for black to develop the bishop on c8 that’s stuck behind two pawns and, thus, the rooks stuck inside their own caves.\r\nWith 14. Rd1, I enable one more piece to participate. Trading a knight and bishop, black makes some room, but this is a distraction from my own plan. As black plays 16. … Ne7, the king is once again limited to the squares c7 and e8, and my bishops are perfectly set up to close these off. 17. Bf7 covers e8. Black simply looks at the bishop with 17. … Rf8. Then 18. Bb6 is mate.\r\nI did not play an excellent game. Many moments of this attack were refutable. For example, if after 17. Bf7 the black king moved to c7, I would have been a bit stuck. However, this was a fast game, played with 5 minutes plus 3 second increments on each move, so my opponent didn’t necessarily have a chance to calculate my plan at each turn. The lesson that I learned from this game is that an aggressive attack can work, even against players who are familiar with some tricks, if the attacking plan is specific and coordinated with the right mistakes made by your opponent. So don’t just trot out the queen! Let your attacks be sound and games be exciting.\r\n\r\n\r\n\r\nBerg, Arthur. 2020. “Statistical Analysis of the Elo Rating System in Chess.” Chance Magazine, September. https://chance.amstat.org/2020/09/chess/.\r\n\r\n\r\n\r\n\r\n",
    "preview": "posts/07_05_21_second/img/elo_rating_resize.png",
    "last_modified": "2021-08-16T15:48:16-04:00",
    "input_file": {}
  },
  {
    "path": "posts/06_21_21_first/",
    "title": "Self-fulfilling prophecies and Big Data",
    "description": "A look at inequality as it's driven by algorithmic thinking. Some advertising \ndata investigation. A discussion of the book \"Weapons of Math Destruction\" \nby Cathy O'Neil.",
    "author": [
      {
        "name": "James Carzon",
        "url": "https://jamescarzon.github.io/"
      }
    ],
    "date": "2021-06-21",
    "categories": [],
    "contents": "\r\n\r\n\r\n\r\nA distinction can be made between the rigorous nature of mathematics and the fuzziness of its applications. Mathematical claims are proved logically and totally. Everything else, one might believe, is only proved to one’s satisfaction or not, but never irrevocably. In the process of translating between Science and Math, something perfect is lost.\r\nThis distinction is a philosophical preface to a long debate on addressing “racist algorithms,” “sexist science,” and so forth. There is a sense in which Big Data are understood to excite inequalities such as wage gaps between racial and gender groups or gaps in job application successes and graduation rates for socioeconomic groups. The gap between science and math constitutes the most immediate criticism of such claims to systemic or social inequality (whatever that means generally) caused (in entirety or in part) by “Big Data.” You know–numbers and stuff. Math. Perfect truth, and the facts that we find when we study the numbers and stuff that are generated and documented by modern technology at an incredible volume.\r\nIt certainly seems to me that these data, like any other data, have no idea what they are describing and that they themselves have no intent to cause anything. They simply arise in the world naturally. It is not the case that “the number of people in academia who consistently vote for Republicans” might be one of perhaps several existing entities conspiring to steepen political bias in higher education. It’s just (possibly) a fact which we (might) observe. So to claim that Big Data are a reason for some sort of inequality of this sort is, obviously, a misunderstanding of what they are.\r\nHowever, there are fairly clear and uncontroversial examples of negative feedback loops which are uniquely enabled by our uses of Big Data which can serve as a clue to the nature of more impactful claims. That is, there are ways in which data and their trained algorithms help to widen measurable inequalities. I have written this post in an attempt to clarify this point of confusion from my personal understanding of the phenomenon of data-driven feedback loops. The idea came to me when I read Cathy O’Neil’s book Weapons of Math Destruction, whose subject matter is the exposure of examples of precisely these sorts of cases. I consider this subject to be one which is too easily dismissed on the basis that it participates in this Math v. Science fallacy, which I hold it does not.\r\nStereotypes arising from data\r\nI am a cautious data scientist, say. I would like to be able to chase a claim from some data set to its source and totally and completely understand the story of that data set’s generation. That would be the ideal way to “do statistics about the world.” This is difficult to do.\r\nFor example, maybe I want to know how my online advertisements are determined. I observe the advertisements which are fed to me and find myself surprised on occasion by which ones I see. Is my phone really spying on me when I’m eating the last of my baby carrots only to inform Google to bump a Domino’s Pizza spot on my Jordan Peterson lecture on YouTube? As a casual experiment, I jumped onto The Grad Cafe, a forum for graduate students from across all of academia, and surveyed the ads I received after a few minutes of browsing: AllState, Hewlett-Packard, Go Daddy, Xfinity and Spectrum, T-Mobile, UWMCareers.com, and the University of Connecticut Pharmacy School. Why do you think I am getting these ads in particular?\r\nOn the one hand, my personal browsing history would suggest that I have spent time recently thinking about insurance and the internet and building websites, et cetera. These are topics that I’ve undoubtedly binge-Binged before. It is plausible that I am shown ads which, among those paid for by companies across the internet, were determined to be most interesting to me by some algorithm.\r\nOn the other hand, I am a user on The Grad Cafe after all and, as such, fit into the demographic of people interested in graduate school. Like many of my peers on the site, I’m in my early ’20s and I have a college degree. I have the time and resources to browse the internet freely and at length. People like me tend to be interested in things like academic careers, pharmacy schools, and cloud computing. It is plausible that I am shown ads which, among those paid for by companies across the internet, were determined to be most interesting to us users of The Grad Cafe.\r\nSince both of these explanations are plausible ones for some or all of the ads I see, I can’t simply x-ray through the results and understand how these choices are being made. I could be judged according to my personal history or I could be judged according to the history of my cohort. In a complex way, I may be judged according to a combination of these.\r\n\r\n\r\n\r\nYou should know that you are welcome to investigate the character of Google’s advertising profile of you. An ad that is provided by Ads by Google should show a triangle button in the top right corner which, when clicked, sends you to an ads settings page. From there you can find a collection of interests for which you’ve been historically pegged.\r\n\r\n\r\n\r\nToday I found out that I am a grains & pasta guy. I did not know this about myself, and had I been adequately tuned in to my body’s cravings I would have hesitated before committing to a keto cleanse that threw me out of lawn maintenance commission for a week and a half of yoga in bed with the lights off. Now I’ll think twice before cutting bread out of my diet, then three times, then four times before caving to a bowl of Frosted Mini Wheats that I can’t finish but do anyways.\r\n\r\n\r\n\r\nThere are several reasons why I have never lost sleep over the threat of an unplanned pregnancy upsetting my assumed way of life, but none of them are that I fail to sense the coming urge of regular bodily functions which, if nightly active, would surely cause me to lose some sleep. Have I forgotten some vast library of videos of clumsy toddlers that my grandma asked me to back up for her in case the family inheritance is pinched by a sleeper cell of the Irish mafia? Maybe that’s an anonymous Reddit account that I’ve forgotten about.\r\n\r\n\r\n\r\nIf you know me, then you know that I need my daily fix of humidifier / dehumidifier mod and app developer news sent to my inbox to start the morning off on a good note. I’m not ashamed to admit that all of my Twitch subscriptions are to water filter and purifier unboxing channels.\r\nThe stereotype that Google has of me is not totally correct, but I saw a bunch of interests which were accurate. This discovery was insightful for me because it inforces a general rule about stereotypes: the farther away from the individual that the data comes, the less accurate its conclusions can dependably be for the individual.\r\nThe negative feedback loop\r\nOver time, Google has inferred these interests of mine from my activity indirectly. As long as the algorithm satisfies me, I reinforce the stereotype. In this example of online advertising, my stereotype is largely benign, but hopefully it is clear that the concept at work can be translated to different contexts. Stereotypes of all kinds are like algorithms. They efficiently approximate the data that we collect, but with that efficiency comes a compromise in accuracy. When we make efficient approximations of someone’s behavior, for example, based on the groups to which they belong, we lose information about their individual peculiarities. This claim, I think, is clear enough.\r\nWhat is the value of a stereotype? If this is a purely sociological question, then it’s difficult to answer it as a statistician. The threats of “Big Data” are well noted, though. Cathy O’Neil’s book Weapons of Math Destruction furnishes a collection of more serious examples of algorithms which are the products of an attitude that squeezing meaning out of Big Data is the way of the future for sociological problems.\r\n\r\n\r\n\r\nFor example, one might look at university rankings to decide to which colleges they should apply, but there is nothing “true” about the University of Virginia being a better place to study than the University of Florida. Maybe if you asked a billion people which one is better, then you can bet that they will favor Virginia in a mass, but that’s not corresponding to any facts of the universe! The US News staff doesn’t count the goodness particles floating in the Gainesville sky and weigh its ranking on that metric. Yet it’s easier for us to steamroll ahead with decisions informed by numbers than to perform a cost-benefit analysis with even less complete data like impressions that we glean from a website and maybe a conversation or two; it’s also easier for university administrators to invest in those features of their university which are relevant to their ranking than to make personal judgment calls on what most needs fixing. Of course, I am now indulging in an oversimplification of both of these processes.\r\nThe assumption underlying these applications of Big Data is that people behave in accordance with categories. Political groups cohere in their decisions, this assumption further suggests, as do ethnic and religious and socioeconomic ones, and so they will be treated according to their group. The problem with this assumption is two-fold. Firstly, it can sharpen ideological boundaries by refining echo chambers and quelling cross-pollination. For example, if politically radical individuals are only recommended politically radical YouTube videos, and if those same videos are rarely recommended to politically opposed individuals, then the consumers of that content may falsely believe their opinions to be widely accepted and not reasonably opposed.\r\nSecondly, it allows for centralized authority. For example, if schoolteachers’ efficacy can be judged by exam scores, then one person with a computer can decide who in a district should be fired by crunching the exam data set and ignoring unmeasurable facts of the exam and the settings in which it was administered. To let all decisions like these be made algorithmically is to decide from the outset that the truth of a judgment is less important than the specificity of it. When authority is centralized, these facts may be lost. So, enabling (and ennobling) algorithms with negative feedback loops of this kind for the purpose of increasing efficiency invites division and ignores local and individual economic peculiarities.\r\nThese two issues seem to invite plenty of extrapolation into political realms which I will not try to do here because I have not even argued for an ethical conclusion to the phenomenon of data-driven feedback loops. I did use the adjective “negative,” which is suggestive, but it’s not an argument. The problem of algorithmic thinking is not “my problem with algorithms.” I am only clarifying an idea which sees itself in these relevant debates.\r\n\r\n\r\n\r\n",
    "preview": "posts/06_21_21_first/img/book_review.png",
    "last_modified": "2021-08-16T13:59:41-04:00",
    "input_file": {}
  }
]
